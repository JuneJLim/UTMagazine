{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: \n",
    "# https://markroxor.github.io/gensim/tutorials/index.html\n",
    "# https://radimrehurek.com/gensim/models/ldamodel.html\n",
    "# https://rstudio-pubs-static.s3.amazonaws.com/79360_850b2a69980c4488b1db95987a24867a.html\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords \n",
    "from gensim import corpora, models\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.wrappers import LdaMallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data\n",
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add('nbsp') # to exclude '&nbsp;' in the text\n",
    "stop_words.add('say') # 'say' and 'says' dominate topic words if not excluded (because our corpus is magazine articles?)\n",
    "stop_words.add('says')\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "for t in df['Content']:\n",
    "    # some contents are 'nan' so exclude them\n",
    "    if type(t) == str:\n",
    "        \n",
    "        # strip html tags\n",
    "        clean = re.compile('<.*?>')\n",
    "        t = re.sub(clean, '', t)\n",
    "        \n",
    "        # lowercase\n",
    "        raw = t.lower()\n",
    "        \n",
    "        # tokenize\n",
    "        tokens = tokenizer.tokenize(raw)\n",
    "        \n",
    "        # remove stop words from tokens\n",
    "        stopped_tokens = [i for i in tokens if not i in stop_words]\n",
    "\n",
    "        # stem tokens\n",
    "        stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "\n",
    "        # add tokens to list\n",
    "        texts.append(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traverses texts assigning a unique integer id to each unique token\n",
    "# while also collecting word counts and relevant statistics\n",
    "# To see each tokenâ€™s unique integer id, try print(dictionary.token2id).\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "# convert the dictionary into a bag-of-words\n",
    "# corpus is a list of vectors equal to the number of documents\n",
    "# each document is a series of tuples; each tuple is (term ID, term frequency)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lda model with 4 topics: [(0, '0.016*\"peopl\" + 0.009*\"work\" + 0.006*\"studi\" + 0.006*\"make\" + 0.006*\"thing\"'), (1, '0.031*\"student\" + 0.027*\"univers\" + 0.012*\"toronto\" + 0.011*\"program\" + 0.011*\"year\"'), (2, '0.012*\"research\" + 0.010*\"health\" + 0.006*\"develop\" + 0.005*\"work\" + 0.005*\"professor\"'), (3, '0.009*\"year\" + 0.006*\"ba\" + 0.005*\"toronto\" + 0.005*\"hous\" + 0.005*\"time\"')]\n",
      "Lda model with 5 topics: [(0, '0.012*\"year\" + 0.011*\"univers\" + 0.011*\"toronto\" + 0.010*\"colleg\" + 0.009*\"student\"'), (1, '0.027*\"student\" + 0.022*\"univers\" + 0.013*\"program\" + 0.010*\"school\" + 0.009*\"year\"'), (2, '0.008*\"citi\" + 0.007*\"design\" + 0.007*\"compani\" + 0.007*\"make\" + 0.007*\"engin\"'), (3, '0.014*\"research\" + 0.013*\"health\" + 0.012*\"peopl\" + 0.009*\"studi\" + 0.007*\"care\"'), (4, '0.009*\"time\" + 0.009*\"peopl\" + 0.008*\"work\" + 0.008*\"day\" + 0.007*\"book\"')]\n",
      "Lda model with 6 topics: [(0, '0.042*\"student\" + 0.031*\"univers\" + 0.016*\"program\" + 0.014*\"year\" + 0.012*\"faculti\"'), (1, '0.011*\"hous\" + 0.010*\"ba\" + 0.010*\"colleg\" + 0.009*\"toronto\" + 0.009*\"univers\"'), (2, '0.010*\"year\" + 0.010*\"work\" + 0.010*\"time\" + 0.008*\"book\" + 0.007*\"day\"'), (3, '0.008*\"citi\" + 0.008*\"compani\" + 0.007*\"technolog\" + 0.007*\"make\" + 0.007*\"comput\"'), (4, '0.015*\"health\" + 0.015*\"research\" + 0.011*\"peopl\" + 0.008*\"care\" + 0.008*\"studi\"'), (5, '0.014*\"peopl\" + 0.009*\"canada\" + 0.007*\"women\" + 0.007*\"world\" + 0.006*\"countri\"')]\n",
      "Lda model with 7 topics: [(0, '0.013*\"univers\" + 0.011*\"colleg\" + 0.011*\"canadian\" + 0.011*\"canada\" + 0.010*\"ba\"'), (1, '0.011*\"time\" + 0.010*\"day\" + 0.010*\"year\" + 0.008*\"team\" + 0.006*\"back\"'), (2, '0.014*\"citi\" + 0.013*\"build\" + 0.013*\"toronto\" + 0.009*\"design\" + 0.008*\"compani\"'), (3, '0.021*\"peopl\" + 0.013*\"health\" + 0.008*\"care\" + 0.007*\"canada\" + 0.007*\"women\"'), (4, '0.012*\"work\" + 0.011*\"book\" + 0.008*\"peopl\" + 0.008*\"write\" + 0.008*\"year\"'), (5, '0.021*\"research\" + 0.009*\"develop\" + 0.008*\"comput\" + 0.008*\"professor\" + 0.007*\"diseas\"'), (6, '0.045*\"student\" + 0.032*\"univers\" + 0.017*\"program\" + 0.014*\"year\" + 0.013*\"faculti\"')]\n",
      "Lda model with 8 topics: [(0, '0.013*\"day\" + 0.013*\"time\" + 0.012*\"year\" + 0.011*\"peopl\" + 0.009*\"work\"'), (1, '0.019*\"health\" + 0.014*\"research\" + 0.011*\"peopl\" + 0.009*\"care\" + 0.009*\"studi\"'), (2, '0.017*\"univers\" + 0.015*\"colleg\" + 0.012*\"toronto\" + 0.011*\"hous\" + 0.011*\"student\"'), (3, '0.013*\"citi\" + 0.010*\"compani\" + 0.009*\"busi\" + 0.008*\"toronto\" + 0.008*\"develop\"'), (4, '0.010*\"research\" + 0.010*\"engin\" + 0.010*\"comput\" + 0.009*\"scienc\" + 0.008*\"technolog\"'), (5, '0.013*\"peopl\" + 0.010*\"canada\" + 0.009*\"women\" + 0.009*\"world\" + 0.008*\"polit\"'), (6, '0.046*\"student\" + 0.034*\"univers\" + 0.019*\"program\" + 0.014*\"year\" + 0.013*\"school\"'), (7, '0.013*\"book\" + 0.010*\"write\" + 0.010*\"work\" + 0.009*\"music\" + 0.009*\"caption\"')]\n",
      "Lda model with 9 topics: [(0, '0.049*\"student\" + 0.035*\"univers\" + 0.019*\"program\" + 0.014*\"year\" + 0.013*\"faculti\"'), (1, '0.013*\"play\" + 0.013*\"year\" + 0.011*\"music\" + 0.009*\"team\" + 0.009*\"show\"'), (2, '0.012*\"compani\" + 0.010*\"comput\" + 0.010*\"technolog\" + 0.010*\"engin\" + 0.007*\"research\"'), (3, '0.024*\"peopl\" + 0.013*\"make\" + 0.010*\"differ\" + 0.010*\"work\" + 0.009*\"thing\"'), (4, '0.013*\"day\" + 0.012*\"year\" + 0.010*\"work\" + 0.010*\"time\" + 0.009*\"stori\"'), (5, '0.015*\"canada\" + 0.013*\"women\" + 0.011*\"countri\" + 0.010*\"peopl\" + 0.010*\"polit\"'), (6, '0.022*\"toronto\" + 0.019*\"citi\" + 0.018*\"build\" + 0.010*\"design\" + 0.010*\"caption\"'), (7, '0.021*\"health\" + 0.018*\"research\" + 0.011*\"care\" + 0.010*\"medic\" + 0.009*\"patient\"'), (8, '0.022*\"univers\" + 0.016*\"colleg\" + 0.014*\"ba\" + 0.011*\"student\" + 0.011*\"canadian\"')]\n",
      "Lda model with 10 topics: [(0, '0.023*\"health\" + 0.017*\"research\" + 0.011*\"medic\" + 0.010*\"care\" + 0.010*\"patient\"'), (1, '0.015*\"women\" + 0.012*\"canada\" + 0.010*\"world\" + 0.010*\"polit\" + 0.009*\"war\"'), (2, '0.026*\"toronto\" + 0.022*\"build\" + 0.022*\"citi\" + 0.012*\"project\" + 0.012*\"design\"'), (3, '0.017*\"book\" + 0.013*\"write\" + 0.011*\"music\" + 0.010*\"art\" + 0.010*\"work\"'), (4, '0.023*\"univers\" + 0.020*\"colleg\" + 0.014*\"ba\" + 0.013*\"year\" + 0.012*\"student\"'), (5, '0.013*\"day\" + 0.009*\"caption\" + 0.009*\"time\" + 0.007*\"year\" + 0.005*\"room\"'), (6, '0.025*\"peopl\" + 0.017*\"work\" + 0.012*\"thing\" + 0.012*\"time\" + 0.012*\"life\"'), (7, '0.057*\"student\" + 0.040*\"univers\" + 0.022*\"program\" + 0.016*\"faculti\" + 0.016*\"research\"'), (8, '0.012*\"busi\" + 0.010*\"compani\" + 0.008*\"manag\" + 0.008*\"canada\" + 0.008*\"peopl\"'), (9, '0.012*\"engin\" + 0.012*\"comput\" + 0.011*\"technolog\" + 0.011*\"research\" + 0.009*\"scienc\"')]\n",
      "Lda model with 11 topics: [(0, '0.025*\"health\" + 0.018*\"research\" + 0.012*\"medic\" + 0.011*\"care\" + 0.011*\"patient\"'), (1, '0.015*\"research\" + 0.013*\"comput\" + 0.013*\"scienc\" + 0.012*\"engin\" + 0.011*\"technolog\"'), (2, '0.052*\"student\" + 0.037*\"univers\" + 0.023*\"program\" + 0.015*\"faculti\" + 0.014*\"research\"'), (3, '0.016*\"day\" + 0.012*\"time\" + 0.009*\"year\" + 0.009*\"back\" + 0.007*\"call\"'), (4, '0.018*\"citi\" + 0.013*\"toronto\" + 0.012*\"compani\" + 0.010*\"busi\" + 0.010*\"build\"'), (5, '0.030*\"peopl\" + 0.014*\"make\" + 0.012*\"work\" + 0.012*\"differ\" + 0.010*\"thing\"'), (6, '0.019*\"book\" + 0.014*\"write\" + 0.013*\"music\" + 0.011*\"art\" + 0.009*\"stori\"'), (7, '0.024*\"canada\" + 0.015*\"world\" + 0.014*\"canadian\" + 0.014*\"countri\" + 0.012*\"polit\"'), (8, '0.015*\"team\" + 0.014*\"caption\" + 0.011*\"year\" + 0.008*\"game\" + 0.007*\"sport\"'), (9, '0.028*\"univers\" + 0.022*\"colleg\" + 0.015*\"student\" + 0.014*\"ba\" + 0.011*\"hous\"'), (10, '0.020*\"women\" + 0.017*\"school\" + 0.016*\"famili\" + 0.016*\"work\" + 0.015*\"year\"')]\n",
      "Lda model with 12 topics: [(0, '0.025*\"peopl\" + 0.016*\"work\" + 0.015*\"thing\" + 0.015*\"make\" + 0.013*\"time\"'), (1, '0.007*\"day\" + 0.007*\"year\" + 0.006*\"time\" + 0.006*\"room\" + 0.006*\"man\"'), (2, '0.028*\"health\" + 0.019*\"peopl\" + 0.015*\"care\" + 0.012*\"studi\" + 0.011*\"children\"'), (3, '0.016*\"canada\" + 0.011*\"govern\" + 0.011*\"countri\" + 0.011*\"polit\" + 0.009*\"canadian\"'), (4, '0.030*\"toronto\" + 0.026*\"build\" + 0.024*\"citi\" + 0.015*\"centr\" + 0.013*\"project\"'), (5, '0.025*\"univers\" + 0.019*\"colleg\" + 0.017*\"ba\" + 0.011*\"year\" + 0.011*\"award\"'), (6, '0.016*\"work\" + 0.013*\"caption\" + 0.013*\"year\" + 0.011*\"day\" + 0.010*\"time\"'), (7, '0.012*\"compani\" + 0.012*\"comput\" + 0.012*\"technolog\" + 0.010*\"engin\" + 0.008*\"system\"'), (8, '0.057*\"student\" + 0.043*\"univers\" + 0.020*\"program\" + 0.015*\"faculti\" + 0.014*\"year\"'), (9, '0.027*\"research\" + 0.012*\"cell\" + 0.011*\"diseas\" + 0.010*\"drug\" + 0.010*\"human\"'), (10, '0.016*\"play\" + 0.015*\"music\" + 0.013*\"team\" + 0.011*\"perform\" + 0.010*\"year\"'), (11, '0.023*\"book\" + 0.015*\"art\" + 0.015*\"studi\" + 0.013*\"write\" + 0.011*\"work\"')]\n",
      "Lda model with 13 topics: [(0, '0.021*\"ba\" + 0.016*\"colleg\" + 0.014*\"music\" + 0.011*\"award\" + 0.011*\"univers\"'), (1, '0.020*\"women\" + 0.018*\"year\" + 0.015*\"work\" + 0.014*\"famili\" + 0.012*\"day\"'), (2, '0.036*\"peopl\" + 0.013*\"thing\" + 0.012*\"make\" + 0.011*\"differ\" + 0.010*\"life\"'), (3, '0.010*\"food\" + 0.007*\"time\" + 0.007*\"day\" + 0.007*\"anim\" + 0.006*\"star\"'), (4, '0.020*\"team\" + 0.014*\"year\" + 0.011*\"time\" + 0.010*\"game\" + 0.009*\"physic\"'), (5, '0.021*\"book\" + 0.016*\"write\" + 0.012*\"stori\" + 0.011*\"work\" + 0.010*\"read\"'), (6, '0.010*\"cent\" + 0.008*\"cost\" + 0.008*\"research\" + 0.008*\"energi\" + 0.007*\"system\"'), (7, '0.018*\"compani\" + 0.016*\"comput\" + 0.015*\"technolog\" + 0.014*\"busi\" + 0.012*\"engin\"'), (8, '0.092*\"student\" + 0.071*\"univers\" + 0.024*\"faculti\" + 0.022*\"year\" + 0.014*\"support\"'), (9, '0.028*\"toronto\" + 0.027*\"citi\" + 0.025*\"build\" + 0.015*\"hous\" + 0.014*\"caption\"'), (10, '0.017*\"canada\" + 0.014*\"polit\" + 0.012*\"world\" + 0.012*\"peopl\" + 0.010*\"countri\"'), (11, '0.024*\"research\" + 0.024*\"school\" + 0.023*\"program\" + 0.015*\"work\" + 0.015*\"world\"'), (12, '0.025*\"health\" + 0.019*\"research\" + 0.013*\"medic\" + 0.012*\"patient\" + 0.011*\"care\"')]\n",
      "Lda model with 14 topics: [(0, '0.023*\"canada\" + 0.016*\"countri\" + 0.015*\"world\" + 0.015*\"polit\" + 0.011*\"intern\"'), (1, '0.015*\"day\" + 0.010*\"back\" + 0.009*\"time\" + 0.009*\"work\" + 0.009*\"year\"'), (2, '0.028*\"women\" + 0.021*\"peopl\" + 0.019*\"children\" + 0.016*\"studi\" + 0.014*\"famili\"'), (3, '0.017*\"music\" + 0.014*\"play\" + 0.013*\"ba\" + 0.012*\"write\" + 0.010*\"film\"'), (4, '0.055*\"univers\" + 0.029*\"student\" + 0.020*\"faculti\" + 0.017*\"research\" + 0.012*\"alumni\"'), (5, '0.068*\"student\" + 0.033*\"school\" + 0.029*\"program\" + 0.024*\"year\" + 0.023*\"work\"'), (6, '0.016*\"team\" + 0.016*\"caption\" + 0.012*\"year\" + 0.010*\"game\" + 0.008*\"sport\"'), (7, '0.014*\"busi\" + 0.013*\"compani\" + 0.010*\"manag\" + 0.009*\"market\" + 0.008*\"product\"'), (8, '0.017*\"univers\" + 0.016*\"colleg\" + 0.014*\"book\" + 0.011*\"histori\" + 0.011*\"ba\"'), (9, '0.029*\"peopl\" + 0.015*\"make\" + 0.013*\"thing\" + 0.011*\"time\" + 0.011*\"differ\"'), (10, '0.018*\"research\" + 0.017*\"comput\" + 0.016*\"engin\" + 0.016*\"technolog\" + 0.015*\"work\"'), (11, '0.011*\"year\" + 0.008*\"time\" + 0.008*\"anim\" + 0.008*\"world\" + 0.007*\"planet\"'), (12, '0.033*\"toronto\" + 0.029*\"build\" + 0.028*\"citi\" + 0.016*\"centr\" + 0.014*\"hous\"'), (13, '0.023*\"health\" + 0.019*\"research\" + 0.014*\"medic\" + 0.013*\"patient\" + 0.012*\"diseas\"')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lda model with 15 topics: [(0, '0.026*\"book\" + 0.017*\"write\" + 0.013*\"work\" + 0.012*\"english\" + 0.011*\"stori\"'), (1, '0.019*\"music\" + 0.015*\"play\" + 0.015*\"art\" + 0.012*\"show\" + 0.012*\"film\"'), (2, '0.040*\"univers\" + 0.023*\"student\" + 0.021*\"research\" + 0.013*\"educ\" + 0.012*\"world\"'), (3, '0.029*\"school\" + 0.020*\"work\" + 0.019*\"children\" + 0.015*\"year\" + 0.014*\"food\"'), (4, '0.037*\"health\" + 0.020*\"care\" + 0.012*\"peopl\" + 0.012*\"hospit\" + 0.012*\"medic\"'), (5, '0.034*\"research\" + 0.015*\"cell\" + 0.011*\"diseas\" + 0.011*\"brain\" + 0.011*\"cancer\"'), (6, '0.019*\"canada\" + 0.014*\"polit\" + 0.012*\"govern\" + 0.012*\"countri\" + 0.009*\"world\"'), (7, '0.031*\"toronto\" + 0.030*\"citi\" + 0.024*\"build\" + 0.016*\"design\" + 0.012*\"hous\"'), (8, '0.082*\"student\" + 0.026*\"univers\" + 0.025*\"program\" + 0.022*\"year\" + 0.019*\"faculti\"'), (9, '0.032*\"peopl\" + 0.014*\"thing\" + 0.012*\"differ\" + 0.012*\"make\" + 0.010*\"feel\"'), (10, '0.024*\"univers\" + 0.019*\"ba\" + 0.017*\"colleg\" + 0.012*\"caption\" + 0.011*\"canada\"'), (11, '0.013*\"day\" + 0.011*\"back\" + 0.009*\"time\" + 0.006*\"year\" + 0.005*\"friend\"'), (12, '0.019*\"compani\" + 0.017*\"busi\" + 0.017*\"comput\" + 0.013*\"technolog\" + 0.010*\"develop\"'), (13, '0.010*\"energi\" + 0.009*\"engin\" + 0.008*\"light\" + 0.008*\"year\" + 0.007*\"water\"'), (14, '0.020*\"team\" + 0.016*\"year\" + 0.011*\"game\" + 0.010*\"time\" + 0.009*\"sport\"')]\n",
      "Lda model with 16 topics: [(0, '0.027*\"book\" + 0.019*\"write\" + 0.015*\"stori\" + 0.014*\"art\" + 0.013*\"work\"'), (1, '0.018*\"music\" + 0.013*\"realli\" + 0.013*\"year\" + 0.013*\"love\" + 0.012*\"peopl\"'), (2, '0.036*\"research\" + 0.016*\"cell\" + 0.012*\"human\" + 0.011*\"brain\" + 0.010*\"cancer\"'), (3, '0.050*\"student\" + 0.022*\"centr\" + 0.021*\"build\" + 0.021*\"000\" + 0.019*\"campu\"'), (4, '0.024*\"canada\" + 0.017*\"govern\" + 0.015*\"canadian\" + 0.014*\"countri\" + 0.011*\"polici\"'), (5, '0.028*\"peopl\" + 0.014*\"make\" + 0.012*\"thing\" + 0.011*\"differ\" + 0.009*\"good\"'), (6, '0.038*\"health\" + 0.020*\"care\" + 0.014*\"medic\" + 0.014*\"patient\" + 0.013*\"dr\"'), (7, '0.035*\"univers\" + 0.020*\"ba\" + 0.017*\"colleg\" + 0.016*\"award\" + 0.014*\"presid\"'), (8, '0.034*\"toronto\" + 0.033*\"citi\" + 0.018*\"caption\" + 0.012*\"design\" + 0.012*\"plan\"'), (9, '0.021*\"compani\" + 0.018*\"busi\" + 0.016*\"comput\" + 0.013*\"technolog\" + 0.010*\"inform\"'), (10, '0.029*\"women\" + 0.018*\"peopl\" + 0.016*\"studi\" + 0.014*\"commun\" + 0.012*\"law\"'), (11, '0.012*\"engin\" + 0.010*\"energi\" + 0.008*\"year\" + 0.008*\"light\" + 0.007*\"water\"'), (12, '0.017*\"team\" + 0.014*\"play\" + 0.012*\"film\" + 0.012*\"year\" + 0.012*\"game\"'), (13, '0.014*\"day\" + 0.008*\"time\" + 0.007*\"call\" + 0.007*\"back\" + 0.006*\"room\"'), (14, '0.026*\"school\" + 0.023*\"work\" + 0.020*\"famili\" + 0.018*\"year\" + 0.018*\"children\"'), (15, '0.054*\"student\" + 0.044*\"univers\" + 0.021*\"program\" + 0.020*\"research\" + 0.016*\"educ\"')]\n",
      "Lda model with 17 topics: [(0, '0.022*\"music\" + 0.020*\"play\" + 0.015*\"perform\" + 0.013*\"film\" + 0.013*\"show\"'), (1, '0.077*\"student\" + 0.033*\"program\" + 0.029*\"school\" + 0.026*\"studi\" + 0.020*\"year\"'), (2, '0.016*\"women\" + 0.016*\"day\" + 0.008*\"men\" + 0.008*\"room\" + 0.007*\"time\"'), (3, '0.030*\"research\" + 0.015*\"cell\" + 0.014*\"comput\" + 0.013*\"human\" + 0.012*\"work\"'), (4, '0.025*\"univers\" + 0.022*\"colleg\" + 0.020*\"ba\" + 0.012*\"award\" + 0.011*\"presid\"'), (5, '0.070*\"univers\" + 0.036*\"student\" + 0.027*\"faculti\" + 0.018*\"research\" + 0.016*\"support\"'), (6, '0.029*\"work\" + 0.027*\"year\" + 0.022*\"famili\" + 0.017*\"children\" + 0.015*\"time\"'), (7, '0.016*\"polit\" + 0.015*\"canada\" + 0.014*\"world\" + 0.013*\"war\" + 0.011*\"countri\"'), (8, '0.024*\"team\" + 0.011*\"energi\" + 0.011*\"game\" + 0.010*\"sport\" + 0.009*\"food\"'), (9, '0.036*\"health\" + 0.016*\"patient\" + 0.016*\"care\" + 0.014*\"medic\" + 0.013*\"hospit\"'), (10, '0.029*\"book\" + 0.019*\"write\" + 0.015*\"stori\" + 0.013*\"english\" + 0.013*\"writer\"'), (11, '0.018*\"public\" + 0.013*\"govern\" + 0.013*\"canada\" + 0.012*\"cent\" + 0.011*\"research\"'), (12, '0.025*\"busi\" + 0.025*\"compani\" + 0.018*\"manag\" + 0.012*\"market\" + 0.011*\"develop\"'), (13, '0.022*\"caption\" + 0.011*\"inform\" + 0.011*\"art\" + 0.011*\"align\" + 0.011*\"id\"'), (14, '0.034*\"toronto\" + 0.034*\"citi\" + 0.032*\"build\" + 0.017*\"design\" + 0.014*\"hous\"'), (15, '0.036*\"peopl\" + 0.016*\"make\" + 0.015*\"thing\" + 0.013*\"differ\" + 0.010*\"person\"'), (16, '0.011*\"time\" + 0.010*\"year\" + 0.009*\"anim\" + 0.008*\"planet\" + 0.007*\"scienc\"')]\n",
      "Lda model with 18 topics: [(0, '0.023*\"peopl\" + 0.013*\"inform\" + 0.011*\"research\" + 0.010*\"problem\" + 0.009*\"person\"'), (1, '0.026*\"compani\" + 0.025*\"busi\" + 0.017*\"manag\" + 0.013*\"work\" + 0.012*\"market\"'), (2, '0.034*\"univers\" + 0.027*\"colleg\" + 0.022*\"ba\" + 0.015*\"student\" + 0.013*\"presid\"'), (3, '0.016*\"polit\" + 0.015*\"canada\" + 0.011*\"world\" + 0.010*\"peopl\" + 0.010*\"countri\"'), (4, '0.014*\"day\" + 0.009*\"back\" + 0.008*\"time\" + 0.006*\"room\" + 0.006*\"night\"'), (5, '0.030*\"school\" + 0.027*\"work\" + 0.025*\"women\" + 0.021*\"famili\" + 0.020*\"year\"'), (6, '0.014*\"comput\" + 0.014*\"engin\" + 0.010*\"technolog\" + 0.010*\"world\" + 0.009*\"scienc\"'), (7, '0.035*\"toronto\" + 0.034*\"build\" + 0.032*\"citi\" + 0.018*\"design\" + 0.015*\"project\"'), (8, '0.023*\"peopl\" + 0.022*\"thing\" + 0.017*\"make\" + 0.013*\"good\" + 0.013*\"life\"'), (9, '0.027*\"music\" + 0.019*\"play\" + 0.015*\"perform\" + 0.013*\"studi\" + 0.009*\"year\"'), (10, '0.052*\"student\" + 0.050*\"univers\" + 0.020*\"program\" + 0.018*\"faculti\" + 0.018*\"research\"'), (11, '0.036*\"research\" + 0.018*\"cell\" + 0.013*\"brain\" + 0.012*\"develop\" + 0.012*\"cancer\"'), (12, '0.035*\"canadian\" + 0.033*\"canada\" + 0.025*\"award\" + 0.020*\"professor\" + 0.020*\"scienc\"'), (13, '0.056*\"student\" + 0.024*\"year\" + 0.021*\"team\" + 0.012*\"game\" + 0.011*\"sport\"'), (14, '0.009*\"energi\" + 0.009*\"cost\" + 0.008*\"environment\" + 0.008*\"chang\" + 0.008*\"year\"'), (15, '0.042*\"health\" + 0.019*\"care\" + 0.016*\"medic\" + 0.016*\"patient\" + 0.015*\"dr\"'), (16, '0.031*\"book\" + 0.020*\"write\" + 0.014*\"english\" + 0.014*\"stori\" + 0.014*\"read\"'), (17, '0.023*\"caption\" + 0.017*\"art\" + 0.016*\"show\" + 0.014*\"film\" + 0.013*\"theatr\"')]\n",
      "Lda model with 19 topics: [(0, '0.027*\"peopl\" + 0.020*\"make\" + 0.017*\"thing\" + 0.013*\"differ\" + 0.011*\"mani\"'), (1, '0.024*\"music\" + 0.021*\"art\" + 0.020*\"play\" + 0.015*\"film\" + 0.015*\"perform\"'), (2, '0.019*\"day\" + 0.014*\"time\" + 0.013*\"year\" + 0.011*\"back\" + 0.008*\"work\"'), (3, '0.024*\"ba\" + 0.017*\"award\" + 0.016*\"univers\" + 0.013*\"canada\" + 0.013*\"toronto\"'), (4, '0.059*\"univers\" + 0.031*\"student\" + 0.024*\"research\" + 0.022*\"faculti\" + 0.014*\"support\"'), (5, '0.021*\"busi\" + 0.021*\"compani\" + 0.017*\"engin\" + 0.013*\"develop\" + 0.012*\"energi\"'), (6, '0.020*\"inform\" + 0.014*\"peopl\" + 0.011*\"work\" + 0.011*\"media\" + 0.011*\"technolog\"'), (7, '0.037*\"citi\" + 0.036*\"toronto\" + 0.030*\"build\" + 0.017*\"design\" + 0.015*\"project\"'), (8, '0.032*\"book\" + 0.024*\"write\" + 0.019*\"stori\" + 0.014*\"writer\" + 0.014*\"work\"'), (9, '0.012*\"cent\" + 0.012*\"govern\" + 0.010*\"public\" + 0.010*\"polici\" + 0.009*\"econom\"'), (10, '0.029*\"women\" + 0.025*\"peopl\" + 0.023*\"studi\" + 0.019*\"children\" + 0.012*\"social\"'), (11, '0.010*\"anim\" + 0.010*\"year\" + 0.009*\"water\" + 0.008*\"travel\" + 0.007*\"air\"'), (12, '0.024*\"team\" + 0.023*\"caption\" + 0.014*\"game\" + 0.012*\"sport\" + 0.012*\"align\"'), (13, '0.029*\"research\" + 0.018*\"cell\" + 0.014*\"brain\" + 0.013*\"cancer\" + 0.012*\"drug\"'), (14, '0.020*\"canada\" + 0.018*\"polit\" + 0.012*\"world\" + 0.012*\"countri\" + 0.012*\"war\"'), (15, '0.015*\"research\" + 0.015*\"scienc\" + 0.014*\"comput\" + 0.010*\"system\" + 0.008*\"work\"'), (16, '0.070*\"student\" + 0.037*\"school\" + 0.037*\"program\" + 0.030*\"year\" + 0.021*\"studi\"'), (17, '0.033*\"student\" + 0.031*\"colleg\" + 0.027*\"univers\" + 0.018*\"hous\" + 0.017*\"campu\"'), (18, '0.047*\"health\" + 0.023*\"care\" + 0.016*\"hospit\" + 0.016*\"dr\" + 0.016*\"medic\"')]\n",
      "Wall time: 17min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# path to the mallet\n",
    "os.environ['MALLET_HOME'] = 'C:/mallet-2.0.8'\n",
    "mallet_path = 'C:/mallet-2.0.8/bin/mallet'\n",
    "\n",
    "# LDA with Mallet implementation (uses Gibbs Sampling)\n",
    "for i in range(4, 20):\n",
    "    # construct a model\n",
    "    ldamodel = LdaMallet(mallet_path, corpus=corpus, num_topics=i, id2word=dictionary)\n",
    "    # save the model as files for later use\n",
    "    ldamodel.save('models/lda_mallet_'+str(i)+'_topics.model')\n",
    "    # print the topics, each represented as 5 words, just to check\n",
    "    print('Lda model with', i, 'topics:', ldamodel.print_topics(num_topics=i, num_words=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# LDA with Gensim implementation (uses Variational Bayes sampling)\n",
    "# I haven't learn this yet; I may compare the result with that of Mallet! \n",
    "for i in range(4, 20):\n",
    "    # construct a model\n",
    "    # passes value (the number of laps the model takes through the corpus) can be changed;\n",
    "    # the larger the number of passes, the more accurate the model will be\n",
    "    ldamodel = LdaModel(corpus=corpus, num_topics=i, id2word=dictionary, passes=20)\n",
    "    # save the model as files for later use\n",
    "    ldamodel.save('models/lda_gensim_'+str(i)+'_topics.model')\n",
    "    # print the topics, each represented as 5 words, just to check\n",
    "    print('Lda model with', i, 'topics:', ldamodel.print_topics(num_topics=i, num_words=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA model with 10 topics (topics are named by me):\n",
    "### topic 0 health research: '0.023*\"health\" + 0.017*\"research\" + 0.011*\"medic\" + 0.010*\"care\" + 0.010*\"patient\" + 0.009*\"diseas\" + 0.008*\"hospit\" + 0.008*\"cell\" + 0.008*\"dr\" + 0.008*\"studi\"'\n",
    "### topic 1 politics and history: 0.015*\"women\" + 0.012*\"canada\" + 0.010*\"world\" + 0.010*\"polit\" + 0.009*\"war\" + 0.008*\"canadian\" + 0.007*\"countri\" + 0.006*\"peopl\" + 0.006*\"histori\" + 0.006*\"intern\"'\n",
    "### topic 2 city of toronto: 0.026*\"toronto\" + 0.022*\"build\" + 0.022*\"citi\" + 0.012*\"project\" + 0.012*\"design\" + 0.010*\"plan\" + 0.010*\"commun\" + 0.009*\"centr\" + 0.009*\"hous\" + 0.009*\"space\"'\n",
    "### topic 3 cultural works: 0.017*\"book\" + 0.013*\"write\" + 0.011*\"music\" + 0.010*\"art\" + 0.010*\"work\" + 0.009*\"stori\" + 0.009*\"play\" + 0.008*\"year\" + 0.008*\"english\" + 0.008*\"writer\"'\n",
    "### topic 4 university: 0.023*\"univers\" + 0.020*\"colleg\" + 0.014*\"ba\" + 0.013*\"year\" + 0.012*\"student\" + 0.011*\"award\" + 0.009*\"toronto\" + 0.008*\"presid\" + 0.008*\"000\" + 0.008*\"alumni\"',\n",
    "### topic 5 time: 0.013*\"day\" + 0.009*\"caption\" + 0.009*\"time\" + 0.007*\"year\" + 0.005*\"room\" + 0.005*\"back\" + 0.005*\"night\" + 0.005*\"food\" + 0.005*\"align\" + 0.005*\"id\"',\n",
    "### topic 6 people: 0.025*\"peopl\" + 0.017*\"work\" + 0.012*\"thing\" + 0.012*\"time\" + 0.012*\"life\" + 0.011*\"make\" + 0.010*\"year\" + 0.010*\"experi\" + 0.010*\"school\" + 0.009*\"differ\"',\n",
    "### topic 7 student: 0.057*\"student\" + 0.040*\"univers\" + 0.022*\"program\" + 0.016*\"faculti\" + 0.016*\"research\" + 0.013*\"year\" + 0.013*\"educ\" + 0.011*\"school\" + 0.010*\"support\" + 0.010*\"academ\"',\n",
    "### topic 8 business: 0.012*\"busi\" + 0.010*\"compani\" + 0.008*\"manag\" + 0.008*\"canada\" + 0.008*\"peopl\" + 0.007*\"cent\" + 0.006*\"chang\" + 0.006*\"govern\" + 0.006*\"market\" + 0.006*\"polici\"',\n",
    "### topic 9 science and technology: 0.012*\"engin\" + 0.012*\"comput\" + 0.011*\"technolog\" + 0.011*\"research\" + 0.009*\"scienc\" + 0.008*\"team\" + 0.007*\"make\" + 0.007*\"world\" + 0.007*\"system\" + 0.007*\"work\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the Mallet LDA model with 10 topics\n",
    "ldamodel = LdaMallet.load(\"lda_mallet_10_topics.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the most likely topic of a document? Let's take an example to see how well the model works. This article #20 in the data file is about a book about World War II written by a U of T professor. Link to the article: https://magazine.utoronto.ca/research-ideas/culture-society/rosemary-sullivan-nazis-in-france-wwii-villa-airbel-emergency-rescue-committee/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.029817953546767105),\n",
       " (1, 0.35091023226616447),\n",
       " (2, 0.04896421845574388),\n",
       " (3, 0.16415568110483364),\n",
       " (4, 0.08505963590709353),\n",
       " (5, 0.10106716886377903),\n",
       " (6, 0.06559949780288764),\n",
       " (7, 0.0354676710608914),\n",
       " (8, 0.09635907093534213),\n",
       " (9, 0.022598870056497175)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel[corpus[20]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The tags attached to the article are BOOKS, HISTORY, and SECOND WORLD WAR. Our model says it is most likely about topic 1 (potlitics) and second most likely about topic 3 (cultural works), which look not too bad! \n",
    "\n",
    "### We can infer the topic of unseen documents and update the model (by ldamodel.update(other_corpus))."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
